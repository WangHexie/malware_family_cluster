import os

import numpy as np
import pandas as pd
from keras.callbacks import ModelCheckpoint
from keras.utils import to_categorical
from keras_preprocessing.sequence import pad_sequences
from sklearn.model_selection import train_test_split

from basic_function import load_dict, load_df, get_root_path, save_dict
from metrics import com_acc
from model import get_model
from shorten_api_list import delete_repeat_pattern, delete_same_pattern
import pickle

shape = (512, 64)
input_dim = 92 + 1
batch_size = 32
epochs = 50
class_num = 2

api_dict = load_dict(os.path.join(get_root_path(), "features", "api_dict.txt"))
white = load_df(os.path.join(get_root_path(), "features", "white"), mode=1)[['file_name', 'api_name', 'call_time']]
black = load_df(os.path.join(get_root_path(), "features", "black"), mode=1)[['file_name', 'api_name', 'call_time']]

white_label = np.zeros(white.shape[0])
black_label = np.ones(black.shape[0])

full = pd.concat([white, black], sort=False)
label = np.concatenate((white_label, black_label))
full['label'] = label

full['api_name'] = full['api_name'].map(api_dict)

# full = load_df(os.path.join(get_root_path(), "features", "stage2"), mode=1)[['file_name', 'api_name', 'call_time']]
full['label'] = np.zeros((full.shape[0],))
full['api_name'] = full['api_name'].map(api_dict)


final_api_list = []
file_name_list = []
label = []

less = False
length = 3
if not less:
    for file_name, api_df in full.groupby('file_name'):
        api_df = api_df.sort_values(by="call_time", axis=0, kind="mergesort")
        final_api_list.append(api_df['api_name'].values)
        label.append(api_df['label'].values[0])
        file_name_list.append(file_name)


    try:
        # pickle.dump(final_api_list,  "./api_list.pk")
        # pickle.dump(label, "./label.pk")
        np.save("api_list_stage2", final_api_list)
        np.save("file_name_list_stage2", file_name_list)
        # np.save("label_", label)
    except:
        print("error")
else:
    for file_name, api_df in full.groupby('file_name'):
        api_df = api_df.sort_values(by="call_time", axis=0, kind="mergesort")
        result = delete_repeat_pattern(api_df['api_name'].values.tolist(), 2)
        result = delete_same_pattern(result, 3)

        final_api_list.append(result)

        label.append(api_df['label'].values[0])
    try:
        save_dict(final_api_list, "./api_list_less.txt")
        save_dict(label, "./label_less.txt")
    except:
        print("error")

# final_api_list = np.load("api_list_stage2.npy")
# label = np.zeros((len(final_api_list)))
# print(api_df)
# print(final_api_list)
fixed_sequence = pad_sequences(final_api_list, maxlen=shape[0], dtype='int32', padding='post', truncating='post',
                               value=input_dim-1)

label = to_categorical(label, num_classes=class_num)
x, x_test, y, y_test = train_test_split(fixed_sequence, label, test_size=0.25)

checkpoint = ModelCheckpoint(filepath='./models/weights.{epoch:02d}-{val_loss:.8f}.hdf5',
                             monitor='val_acc',
                             verbose=1,
                             save_best_only=False)

callbacks = [checkpoint]

model = get_model(shape=shape, model_type=6, n=1, input_dim=input_dim, class_num=class_num, use_attention=True)
for i in range(epochs):
    model.fit(np.array(x), y,
              batch_size=batch_size,
              epochs=1,
              validation_data=(np.array(x_test), y_test),
              shuffle=True,
              callbacks=callbacks)

    predictions = model.predict(np.array(x_test))[:, 1]
    acc = com_acc(np.array(y_test)[:, 1].flatten(), predictions.flatten(), 0.1)
    print("valid:", acc, 0.1)

    acc = com_acc(np.array(y_test)[:, 1].flatten(), predictions.flatten(), 0.3)
    print("valid:", acc, 0.3)

    acc = com_acc(np.array(y_test)[:, 1].flatten(), predictions.flatten(), 0.5)
    print("valid:", acc, 0.5)

    acc = com_acc(np.array(y_test)[:, 1].flatten(), predictions.flatten(), 0.6)
    print("valid:", acc, 0.6)

    acc = com_acc(np.array(y_test)[:, 1].flatten(), predictions.flatten(), 0.7)
    print("valid:", acc, 0.7)

    acc = com_acc(np.array(y_test)[:, 1].flatten(), predictions.flatten(), 0.9)
    print("valid:", acc, 0.9)


